(window.webpackJsonp=window.webpackJsonp||[]).push([[68],{640:function(s,e,a){"use strict";a.r(e);var t=a(5),n=Object(t.a)({},(function(){var s=this,e=s.$createElement,a=s._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("p",[s._v("As a big data enthusiast, if you are interested to learn Apache Hive, this blog will help you set it up on your local in few easy steps. This setup will serve as a good starting point for beginners as it will simulate the production environment.\nThis tutorial uses Docker containers to spin up Apache Hive. Before we jump right into it, here is a quick overview of some of the critical components in this cluster.")]),s._v(" "),a("h1",{attrs:{id:"apache-hive"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#apache-hive"}},[s._v("#")]),s._v(" Apache Hive:")]),s._v(" "),a("p",[s._v("Apache Hive is a distributed, fault-tolerant data warehouse system that enables analytics of large datasets residing in distributed storage using SQL.")]),s._v(" "),a("h1",{attrs:{id:"docker"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#docker"}},[s._v("#")]),s._v(" Docker:")]),s._v(" "),a("p",[s._v("Docker is an open-source technology to package an application and all its dependencies into a container.")]),s._v(" "),a("h1",{attrs:{id:"namenode"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#namenode"}},[s._v("#")]),s._v(" NameNode:")]),s._v(" "),a("p",[s._v("The NameNode is at the core of the Hadoop cluster. It keeps the directory tree of all files in the file system, and tracks where the file data is actually kept in the cluster.")]),s._v(" "),a("h1",{attrs:{id:"datanode"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#datanode"}},[s._v("#")]),s._v(" DataNode:")]),s._v(" "),a("p",[s._v("The DataNode on the other hand stores the actual file data. Files are replicated across multiple DataNodes in a cluster for reliability.\nSpecifically, if were to think in terms of Hive, the data stored on the Hive tables is spread across the DataNodes within the cluster. NameNode, on the other hand is the one keeping track of these blocks of data actually stored on the DataNodes.\nWe are using a single DataNode in this tutorial for the sake of simplicity.")]),s._v(" "),a("h1",{attrs:{id:"hive-metastore"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hive-metastore"}},[s._v("#")]),s._v(" Hive Metastore:")]),s._v(" "),a("p",[s._v("Hive uses a relational database to store the metadata (e.g. schema and location) of all its tables. The default database is Derby, but we will be using PostgreSQL in this tutorial.\nThe key benefit of using a relational database over HDFS is low latency and improved performance.")]),s._v(" "),a("h1",{attrs:{id:"volumes"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#volumes"}},[s._v("#")]),s._v(" Volumes:")]),s._v(" "),a("p",[s._v("Volumes are the preferred mechanism for persisting data generated by and used by Docker containers.\nVolumes also allow us to persist the container state between subsequent docker runs.\nIf you don’t explicitly create it, a volume is created the first time it is mounted into a container. When that container stops or is removed, the volume still exists. Specifically, in this use case, we are using volumes inside NameNode and DataNode containers to persist the HDFS file system. The volume on PostgreSQL container is utilized to persist the meta-data of the previously created Hive tables.")]),s._v(" "),a("h1",{attrs:{id:"pre-requisites"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#pre-requisites"}},[s._v("#")]),s._v(" Pre-requisites:")]),s._v(" "),a("p",[s._v("The only pre-requisite is Docker. I’m running it on Macbook Pro with 8 GB RAM. Installing Docker is pretty straightforward. Please follow the instructions on https://docs.docker.com/docker-for-mac/install/ to install it if you do not have it already on your machine.")]),s._v(" "),a("h1",{attrs:{id:"_1-directory-structure"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-directory-structure"}},[s._v("#")]),s._v(" 1. Directory Structure:")]),s._v(" "),a("p",[s._v("Create the directory structure on your local")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[s._v("mkdir")]),s._v(" Hive\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("cd")]),s._v(" Hive\n"),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("touch")]),s._v(" docker-compose.yml\n"),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("touch")]),s._v(" hadoop-hive.env\n"),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("mkdir")]),s._v(" employee\n"),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("cd")]),s._v(" employee\n"),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("touch")]),s._v(" employee_table.hql\n"),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("touch")]),s._v(" employee.csv\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br")])]),a("h1",{attrs:{id:"_2-edit-files"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-edit-files"}},[s._v("#")]),s._v(" 2. Edit files:")]),s._v(" "),a("p",[s._v("Open each file in your favorite editor and simply paste the below code snippets in them.")]),s._v(" "),a("h2",{attrs:{id:"docker-compose-yml"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#docker-compose-yml"}},[s._v("#")]),s._v(" docker-compose.yml:")]),s._v(" "),a("p",[s._v("Compose is a Docker tool for defining and running multi-container Docker applications. We are using the below YAML file to configure the services required by our Hive cluster. The biggest advantage of using Compose is that it creates and starts all the services using a single command.")]),s._v(" "),a("div",{staticClass:"language-yml line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-yml"}},[a("code",[a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("version")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'3'")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("services")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("namenode")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("image")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" bde2020/hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("namenode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("2.0.0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("hadoop2.7.4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("java8\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("container_name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" namenode\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("volumes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" ./hdfs/namenode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("/hadoop/dfs/name\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("environment")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" CLUSTER_NAME=hive\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("env_file")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" ./hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("hive.env\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("ports")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"50070:50070"')]),s._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("datanode")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("image")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" bde2020/hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("datanode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("2.0.0"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("hadoop2.7.4"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("java8\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("container_name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" datanode\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("volumes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" ./hdfs/datanode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("/hadoop/dfs/data\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("env_file")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" ./hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("hive.env\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("environment")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("SERVICE_PRECONDITION")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"namenode:50070"')]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("depends_on")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" namenode\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("ports")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"50075:50075"')]),s._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("hive-server")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("image")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" bde2020/hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("2.3.2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("postgresql"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("metastore\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("container_name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("server\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("volumes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" ./employee"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("/employee\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("env_file")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" ./hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("hive.env\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("environment")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("HIVE_CORE_CONF_javax_jdo_option_ConnectionURL")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"jdbc:postgresql://hive-metastore/metastore"')]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("SERVICE_PRECONDITION")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"hive-metastore:9083"')]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("depends_on")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("metastore\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("ports")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"10000:10000"')]),s._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("hive-metastore")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("image")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" bde2020/hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("2.3.2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("postgresql"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("metastore\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("container_name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("metastore\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("env_file")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" ./hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("hive.env\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("command")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" /opt/hive/bin/hive "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("service metastore\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("environment")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("SERVICE_PRECONDITION")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"namenode:50070 datanode:50075 hive-metastore-postgresql:5432"')]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("depends_on")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("metastore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("postgresql\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("ports")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v('"9083:9083"')]),s._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("hive-metastore-postgresql")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("image")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" bde2020/hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("metastore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("postgresql"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("2.3.0\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("container_name")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" hive"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("metastore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("postgresql\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("volumes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" ./metastore"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v("postgresql/postgresql/data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("/var/lib/postgresql/data\n    "),a("span",{pre:!0,attrs:{class:"token key atrule"}},[s._v("depends_on")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v("\n      "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("-")]),s._v(" datanode\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br"),a("span",{staticClass:"line-number"},[s._v("35")]),a("br"),a("span",{staticClass:"line-number"},[s._v("36")]),a("br"),a("span",{staticClass:"line-number"},[s._v("37")]),a("br"),a("span",{staticClass:"line-number"},[s._v("38")]),a("br"),a("span",{staticClass:"line-number"},[s._v("39")]),a("br"),a("span",{staticClass:"line-number"},[s._v("40")]),a("br"),a("span",{staticClass:"line-number"},[s._v("41")]),a("br"),a("span",{staticClass:"line-number"},[s._v("42")]),a("br"),a("span",{staticClass:"line-number"},[s._v("43")]),a("br"),a("span",{staticClass:"line-number"},[s._v("44")]),a("br"),a("span",{staticClass:"line-number"},[s._v("45")]),a("br"),a("span",{staticClass:"line-number"},[s._v("46")]),a("br"),a("span",{staticClass:"line-number"},[s._v("47")]),a("br"),a("span",{staticClass:"line-number"},[s._v("48")]),a("br"),a("span",{staticClass:"line-number"},[s._v("49")]),a("br"),a("span",{staticClass:"line-number"},[s._v("50")]),a("br"),a("span",{staticClass:"line-number"},[s._v("51")]),a("br"),a("span",{staticClass:"line-number"},[s._v("52")]),a("br"),a("span",{staticClass:"line-number"},[s._v("53")]),a("br"),a("span",{staticClass:"line-number"},[s._v("54")]),a("br"),a("span",{staticClass:"line-number"},[s._v("55")]),a("br"),a("span",{staticClass:"line-number"},[s._v("56")]),a("br"),a("span",{staticClass:"line-number"},[s._v("57")]),a("br"),a("span",{staticClass:"line-number"},[s._v("58")]),a("br"),a("span",{staticClass:"line-number"},[s._v("59")]),a("br"),a("span",{staticClass:"line-number"},[s._v("60")]),a("br"),a("span",{staticClass:"line-number"},[s._v("61")]),a("br"),a("span",{staticClass:"line-number"},[s._v("62")]),a("br"),a("span",{staticClass:"line-number"},[s._v("63")]),a("br"),a("span",{staticClass:"line-number"},[s._v("64")]),a("br")])]),a("h2",{attrs:{id:"hadoop-hive-env"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hadoop-hive-env"}},[s._v("#")]),s._v(" hadoop-hive.env:")]),s._v(" "),a("p",[s._v("The .env file is used to set the working enviornment variables.")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore-postgresql/metastore\nHIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.Driver\nHIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hive\nHIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=hive\nHIVE_SITE_CONF_datanucleus_autoCreateSchema=false\nHIVE_SITE_CONF_hive_metastore_uris=thrift://hive-metastore:9083\n\nCORE_CONF_fs_defaultFS=hdfs://namenode:8020\nCORE_CONF_hadoop_http_staticuser_user=root\nCORE_CONF_hadoop_proxyuser_hue_hosts=*\nCORE_CONF_hadoop_proxyuser_hue_groups=*\n\nHDFS_CONF_dfs_webhdfs_enabled=true\nHDFS_CONF_dfs_permissions_enabled=false\n\nYARN_CONF_yarn_log___aggregation___enable=true\nYARN_CONF_yarn_resourcemanager_recovery_enabled=true\nYARN_CONF_yarn_resourcemanager_store_class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore\nYARN_CONF_yarn_resourcemanager_fs_state___store_uri=/rmstate\nYARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logs\nYARN_CONF_yarn_log_server_url=http://historyserver:8188/applicationhistory/logs/\nYARN_CONF_yarn_timeline___service_enabled=true\nYARN_CONF_yarn_timeline___service_generic___application___history_enabled=true\nYARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled=true\nYARN_CONF_yarn_resourcemanager_hostname=resourcemanager\nYARN_CONF_yarn_timeline___service_hostname=historyserver\nYARN_CONF_yarn_resourcemanager_address=resourcemanager:8032\nYARN_CONF_yarn_resourcemanager_scheduler_address=resourcemanager:8030\nYARN_CONF_yarn_resourcemanager_resource__tracker_address=resourcemanager:8031\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br")])]),a("h2",{attrs:{id:"employee-table-hql"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#employee-table-hql"}},[s._v("#")]),s._v(" employee_table.hql:")]),s._v(" "),a("p",[s._v("This HQL script will be later used in the tutorial to demonstrate the creation of a sample Hive Database and Table. As soon as docker spins up the hive-server container, this file will be automatically mounted inside it for use.")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("create database "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" not exists testdb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nuse testdb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\ncreate external table "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" not exists employee "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("\n  eid int,\n  ename string,\n  age int,\n  jobtype string,\n  storeid int,\n  storelocation string,\n  salary bigint,\n  yrsofexp int\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nrow "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("format")]),s._v(" delimited\nfields terminated by "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("','")]),s._v("\nlines terminated by "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'"),a("span",{pre:!0,attrs:{class:"token entity",title:"\\n"}},[s._v("\\n")]),s._v("'")]),s._v("\nstored as textfile location "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'hdfs://namenode:8020/user/hive/warehouse/testdb.db/employee'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br")])]),a("h2",{attrs:{id:"employee-csv"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#employee-csv"}},[s._v("#")]),s._v(" employee.csv:")]),s._v(" "),a("p",[s._v("This csv file contains some sample records which will be loaded into the employee table. Again, this file is automatically mounted by docker inside the hive-server container at start up.")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("1,Rudolf Bardin,30,cashier,100,New York,40000,5\n2,Rob Trask,22,driver,100,New York,50000,4\n3,Madie Nakamura,20,janitor,100,New York,30000,4\n4,Alesha Huntley,40,cashier,101,Los Angeles,40000,10\n5,Iva Moose,50,cashier,102,Phoenix,50000,20\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("h1",{attrs:{id:"_3-create-start-all-services"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-create-start-all-services"}},[s._v("#")]),s._v(" 3. Create & Start all services:")]),s._v(" "),a("p",[s._v("Navigate inside the Hive directory on your local and run the single docker compose command to create and start all services required by our Hive cluster.")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("docker-compose up\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("h1",{attrs:{id:"_4-verify-container-status"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-verify-container-status"}},[s._v("#")]),s._v(" 4. Verify container status:")]),s._v(" "),a("p",[s._v("Allow Docker a few minutes to spin up all the containers. I use couple of ways to confirm that the required services are up and running.\nLook for the below message in the logs once you run docker-compose up.")]),s._v(" "),a("p",[s._v("Snapshot of docker-compose up logs\nRun the command docker stats in another terminal. As docker begins to spin up the containers, their CPU and Memory utilization will stabilize after a few minutes in absence of any other activity on the cluster.")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("docker stats\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("CONTAINER ID   NAME                        CPU %     MEM USAGE / LIMIT     MEM %     NET I/O           BLOCK I/O         PIDS\n8cfdc9ea3002   hive-server                 0.39%     184.7MiB / 1.941GiB   9.30%     25.5kB / 30.5kB   1.63MB / 659kB    27\n938e98165aa7   hive-metastore              0.39%     191.7MiB / 1.941GiB   9.65%     182kB / 213kB     2.75MB / 164kB    22\n1e8ddecb96de   hive-metastore-postgresql   0.46%     26.36MiB / 1.941GiB   1.33%     207kB / 176kB     2.13MB / 2.14MB   10\n2d4c1ed7ed9d   datanode                    0.13%     112.9MiB / 1.941GiB   5.68%     67.8kB / 324kB    623kB / 156kB     44\nc4b2af14a4cb   namenode                    0.13%     121MiB / 1.941GiB     6.09%     350kB / 82.6kB    1.56MB / 1.23MB  \n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("h1",{attrs:{id:"_5-demo"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_5-demo"}},[s._v("#")]),s._v(" 5. Demo:")]),s._v(" "),a("p",[s._v("Its time for a quick demo! Log onto the Hive-server and create a sample database and hive table by executing the below command in a new terminal.")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("docker "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("exec")]),s._v(" -it hive-server /bin/bash\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("Navigate to the employee directory on the hive-server container.")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("root@dc86b2b9e566:/opt"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ls")]),s._v("\nhadoop-2.7.4  hive\nroot@dc86b2b9e566:/opt"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# cd ..")]),s._v("\nroot@dc86b2b9e566:/"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ls")]),s._v("\nbin  boot  dev employee  entrypoint.sh  etc  hadoop-data  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\nroot@dc86b2b9e566:/"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# cd employee/")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br")])]),a("p",[s._v("Execute the employee_table.hql to create a new external hive table employee under a new database testdb.")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("root@dc86b2b9e566:/employee"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hive -f employee_table.hql")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("Now, let’s add some data to this hive table. For that, simply push the employee.csv present in the employee directory on the hive-server into HDFS.")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("root@dc86b2b9e566:/employee"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -put employee.csv hdfs://namenode:8020/user/hive/warehouse/testdb.db/employee")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("h1",{attrs:{id:"_6-validate-the-setup"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_6-validate-the-setup"}},[s._v("#")]),s._v(" 6. Validate the setup:")]),s._v(" "),a("p",[s._v("On the hive-server, launch hive to verify the contents of the employee table.")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("root@df1ac619536c:/employee"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hive")]),s._v("\nhive"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" show databases"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nOK\ndefault\ntestdb\nTime taken: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2.363")]),s._v(" seconds, Fetched: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\nhive"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" use testdb"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nOK\nTime taken: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.085")]),s._v(" seconds\nhive"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" * from employee"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nOK\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" Rudolf Bardin "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),s._v(" cashier "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v(" New York "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("40000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" Rob Trask "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" driver "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v(" New York "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("50000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" Madie Nakamura "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),s._v(" janitor "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v(" New York "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("30000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" Alesha Huntley "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("40")]),s._v(" cashier "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("101")]),s._v(" Los Angeles "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("40000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" Iva Moose "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),s._v(" cashier "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),s._v(" Phoenix "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("50000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),s._v("\nTime taken: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.237")]),s._v(" seconds, Fetched: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br")])]),a("h1",{attrs:{id:"_7-validate-the-container-state-between-subsequent-docker-runs"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_7-validate-the-container-state-between-subsequent-docker-runs"}},[s._v("#")]),s._v(" 7. Validate the container state between subsequent docker runs:")]),s._v(" "),a("p",[s._v("All good so far. You have successfully created a Apache Hive cluster on Docker.\nIt is critical to verify that the Hive tables are maintained between subsequent docker runs and we do not end up losing our progress if docker containers are stopped. Therefore, restart the docker containers and verify that the hive data is persisted or not.\nIn a new terminal, execute below command to stop all docker containers.")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("docker-compose down\nStopping hive-server               "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\nStopping hive-metastore            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\nStopping hive-metastore-postgresql "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\nStopping datanode                  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\nStopping namenode                  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\nRemoving hive-server               "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\nRemoving hive-metastore            "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\nRemoving hive-metastore-postgresql "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\nRemoving datanode                  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\nRemoving namenode                  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("..")]),s._v(". "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("done")]),s._v("\nRemoving network hive_default\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br")])]),a("p",[s._v("Once all containers are stopped, run docker-compose up one more time.")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("docker-compose up\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("Wait for a few minutes as suggested in step 4 for the containers to come back online, then log onto the hive-server and run the select query.")]),s._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[s._v("docker "),a("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("exec")]),s._v(" -it hive-server /bin/bash\nroot@df1ac619536c:/opt"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hive")]),s._v("\nhive"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("select")]),s._v(" * from testdb.employee"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\nOK\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" Rudolf Bardin "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),s._v(" cashier "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v(" New York "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("40000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v(" Rob Trask "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" driver "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v(" New York "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("50000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" Madie Nakamura "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),s._v(" janitor "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v(" New York "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("30000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),s._v(" Alesha Huntley "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("40")]),s._v(" cashier "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("101")]),s._v(" Los Angeles "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("40000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" Iva Moose "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("50")]),s._v(" cashier "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("102")]),s._v(" Phoenix "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("50000")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),s._v("\nTime taken: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("4.237")]),s._v(" seconds, Fetched: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),s._v(" row"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br")])]),a("p",[s._v("Hurray! We still have our data!\nCongratulations on setting up your hive server on Docker! Keep practicing!")])])}),[],!1,null,null,null);e.default=n.exports}}]);